# 第一步：
我先拿文档（干干净净的）txt，利用LLM循环策略来进行文档切块和实体提取，并生成多源数据集（单步、聚合、多跳、COT）

然后我拿识别出来的实体 进行人工反馈 进行标签修正 得到NER训练标注数据

使用BERT或FinBERT训练NER模型

# 第二步：
对json知识文档进行NER识别，识别每一个知识块的实体信息

# 第三步：
第一步干净的文档+
知识库+该知识库的实体信息给到LLM，进行关系提取和关键词识别

# 第四步：构建倒排索引+知识图谱数据库

# 第五步：每一个类别的检索器设计好

# 第六步：第一步生成的问题，进行类别标注（用于意图识别和embed负样本检索）
然后1. 训练意图识别模型
2. 收集embedding的负样本数据 训练embedding模型